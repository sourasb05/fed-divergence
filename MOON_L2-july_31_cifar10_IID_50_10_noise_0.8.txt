============================================================
Summary of training process:
FL Algorithm: MOON_L2
model: CNN
optimizer: SGD
Batch size: 124
Global_iters: 200
Local_iters: 10
experiments: 1
device : 0
Learning rate: 0.01
============================================================
/proj/bhuyan24/fed-divergence
CIFAR10
./data/data/noisy/0.8_50_10/train/cifa_train.json
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:44<2:27:00, 44.32s/it]  1%|          | 2/200 [01:17<2:05:16, 37.96s/it]  2%|▏         | 3/200 [01:50<1:57:03, 35.65s/it]  2%|▏         | 4/200 [02:23<1:53:05, 34.62s/it]  2%|▎         | 5/200 [02:56<1:49:56, 33.83s/it]  3%|▎         | 6/200 [03:28<1:48:02, 33.41s/it]  4%|▎         | 7/200 [04:01<1:46:12, 33.02s/it]  4%|▍         | 8/200 [04:33<1:45:00, 32.81s/it]  4%|▍         | 9/200 [05:05<1:43:39, 32.57s/it]  5%|▌         | 10/200 [05:37<1:42:36, 32.40s/it]  6%|▌         | 11/200 [06:09<1:41:24, 32.20s/it]  6%|▌         | 12/200 [06:41<1:40:47, 32.17s/it]  6%|▋         | 13/200 [07:13<1:39:50, 32.03s/it]  7%|▋         | 14/200 [07:44<1:39:11, 32.00s/it]  8%|▊         | 15/200 [08:17<1:38:53, 32.07s/it]  8%|▊         | 16/200 [08:49<1:38:13, 32.03s/it]  8%|▊         | 17/200 [09:21<1:37:56, 32.11s/it]  9%|▉         | 18/200 [09:53<1:37:22, 32.10s/it] 10%|▉         | 19/200 [10:25<1:36:43, 32.06s/it] 10%|█         | 20/200 [10:57<1:35:44, 31.91s/it] 10%|█         | 21/200 [11:29<1:35:21, 31.96s/it] 11%|█         | 22/200 [12:01<1:34:48, 31.96s/it] 12%|█▏        | 23/200 [12:33<1:34:25, 32.01s/it] 12%|█▏        | 24/200 [13:05<1:34:02, 32.06s/it] 12%|█▎        | 25/200 [13:37<1:33:55, 32.20s/it] 13%|█▎        | 26/200 [14:09<1:32:59, 32.07s/it] 14%|█▎        | 27/200 [14:41<1:32:15, 31.99s/it] 14%|█▍        | 28/200 [15:13<1:31:50, 32.04s/it] 14%|█▍        | 29/200 [15:45<1:31:06, 31.97s/it] 15%|█▌        | 30/200 [16:17<1:30:36, 31.98s/it] 16%|█▌        | 31/200 [16:49<1:29:47, 31.88s/it] 16%|█▌        | 32/200 [17:20<1:29:14, 31.87s/it] 16%|█▋        | 33/200 [17:52<1:28:15, 31.71s/it] 17%|█▋        | 34/200 [18:23<1:27:43, 31.71s/it] 18%|█▊        | 35/200 [18:55<1:26:54, 31.60s/it] 18%|█▊        | 36/200 [19:27<1:26:31, 31.66s/it] 18%|█▊        | 37/200 [19:58<1:26:00, 31.66s/it] 19%|█▉        | 38/200 [20:31<1:26:04, 31.88s/it] 20%|█▉        | 39/200 [21:02<1:25:29, 31.86s/it] 20%|██        | 40/200 [21:35<1:25:23, 32.02s/it] 20%|██        | 41/200 [22:07<1:24:48, 32.00s/it] 21%|██        | 42/200 [22:39<1:24:20, 32.03s/it] 22%|██▏       | 43/200 [23:11<1:23:47, 32.02s/it] 22%|██▏       | 44/200 [23:43<1:23:03, 31.94s/it] 22%|██▎       | 45/200 [24:15<1:22:31, 31.95s/it] 23%|██▎       | 46/200 [24:46<1:21:48, 31.87s/it] 24%|██▎       | 47/200 [25:18<1:21:13, 31.85s/it] 24%|██▍       | 48/200 [25:50<1:20:31, 31.79s/it] 24%|██▍       | 49/200 [26:22<1:20:03, 31.81s/it] 25%|██▌       | 50/200 [26:53<1:19:28, 31.79s/it] 26%|██▌       | 51/200 [27:26<1:19:21, 31.96s/it] 26%|██▌       | 52/200 [27:57<1:18:34, 31.86s/it] 26%|██▋       | 53/200 [28:30<1:18:23, 32.00s/it] 27%|██▋       | 54/200 [29:02<1:17:59, 32.05s/it] 28%|██▊       | 55/200 [29:34<1:17:23, 32.02s/it] 28%|██▊       | 56/200 [30:06<1:16:45, 31.98s/it] 28%|██▊       | 57/200 [30:37<1:16:02, 31.91s/it] 29%|██▉       | 58/200 [31:09<1:15:24, 31.86s/it] 30%|██▉       | 59/200 [31:41<1:14:40, 31.78s/it] 30%|███       | 60/200 [32:14<1:14:54, 32.10s/it] 30%|███       | 61/200 [32:46<1:14:19, 32.08s/it] 31%|███       | 62/200 [33:19<1:14:27, 32.37s/it] 32%|███▏      | 63/200 [33:51<1:13:42, 32.28s/it] 32%|███▏      | 64/200 [34:23<1:12:56, 32.18s/it] 32%|███▎      | 65/200 [34:54<1:12:06, 32.05s/it] 33%|███▎      | 66/200 [35:26<1:11:27, 32.00s/it] 34%|███▎      | 67/200 [35:58<1:10:47, 31.94s/it] 34%|███▍      | 68/200 [36:30<1:10:05, 31.86s/it] 34%|███▍      | 69/200 [37:02<1:09:36, 31.88s/it] 35%|███▌      | 70/200 [37:33<1:08:58, 31.83s/it] 36%|███▌      | 71/200 [38:05<1:08:25, 31.82s/it] 36%|███▌      | 72/200 [38:37<1:07:41, 31.73s/it] 36%|███▋      | 73/200 [39:09<1:07:13, 31.76s/it] 37%|███▋      | 74/200 [39:40<1:06:30, 31.67s/it] 38%|███▊      | 75/200 [40:12<1:05:58, 31.66s/it] 38%|███▊      | 76/200 [40:43<1:05:21, 31.62s/it] 38%|███▊      | 77/200 [41:15<1:04:51, 31.64s/it] 39%|███▉      | 78/200 [41:47<1:04:26, 31.69s/it] 40%|███▉      | 79/200 [42:19<1:04:11, 31.83s/it] 40%|████      | 80/200 [42:51<1:03:36, 31.80s/it] 40%|████      | 81/200 [43:22<1:02:56, 31.73s/it] 41%|████      | 82/200 [43:54<1:02:18, 31.69s/it] 42%|████▏     | 83/200 [44:25<1:01:44, 31.66s/it] 42%|████▏     | 84/200 [44:57<1:01:16, 31.69s/it] 42%|████▎     | 85/200 [45:29<1:00:38, 31.64s/it] 43%|████▎     | 86/200 [46:00<1:00:12, 31.69s/it] 44%|████▎     | 87/200 [46:32<59:34, 31.63s/it]   44%|████▍     | 88/200 [47:04<59:07, 31.67s/it] 44%|████▍     | 89/200 [47:35<58:34, 31.66s/it] 45%|████▌     | 90/200 [48:07<58:07, 31.70s/it] 46%|████▌     | 91/200 [48:39<57:32, 31.67s/it] 46%|████▌     | 92/200 [49:11<57:27, 31.93s/it] 46%|████▋     | 93/200 [49:43<56:58, 31.95s/it] 47%|████▋     | 94/200 [50:15<56:22, 31.91s/it] 48%|████▊     | 95/200 [50:47<55:43, 31.84s/it] 48%|████▊     | 96/200 [51:19<55:25, 31.97s/it] 48%|████▊     | 97/200 [51:51<54:58, 32.02s/it] 49%|████▉     | 98/200 [52:23<54:27, 32.04s/it] 50%|████▉     | 99/200 [52:55<53:56, 32.05s/it] 50%|█████     | 100/200 [53:27<53:28, 32.08s/it] 50%|█████     | 101/200 [54:00<53:03, 32.16s/it] 51%|█████     | 102/200 [54:32<52:25, 32.10s/it] 52%|█████▏    | 103/200 [55:04<51:53, 32.10s/it] 52%|█████▏    | 104/200 [55:36<51:16, 32.05s/it] 52%|█████▎    | 105/200 [56:08<50:42, 32.03s/it] 53%|█████▎    | 106/200 [56:39<49:55, 31.86s/it] 54%|█████▎    | 107/200 [57:11<49:16, 31.79s/it] 54%|█████▍    | 108/200 [57:43<48:41, 31.76s/it] 55%|█████▍    | 109/200 [58:14<48:14, 31.80s/it] 55%|█████▌    | 110/200 [58:46<47:37, 31.75s/it] 56%|█████▌    | 111/200 [59:18<47:05, 31.75s/it] 56%|█████▌    | 112/200 [59:50<46:39, 31.81s/it] 56%|█████▋    | 113/200 [1:00:21<46:03, 31.76s/it] 57%|█████▋    | 114/200 [1:00:53<45:35, 31.80s/it] 57%|█████▊    | 115/200 [1:01:25<45:05, 31.83s/it] 58%|█████▊    | 116/200 [1:01:57<44:40, 31.91s/it] 58%|█████▊    | 117/200 [1:02:29<44:06, 31.88s/it] 59%|█████▉    | 118/200 [1:03:01<43:36, 31.91s/it] 60%|█████▉    | 119/200 [1:03:33<43:03, 31.90s/it] 60%|██████    | 120/200 [1:04:05<42:38, 31.98s/it] 60%|██████    | 121/200 [1:04:37<42:03, 31.94s/it] 61%|██████    | 122/200 [1:05:09<41:32, 31.96s/it] 62%|██████▏   | 123/200 [1:05:41<40:56, 31.90s/it] 62%|██████▏   | 124/200 [1:06:13<40:29, 31.96s/it] 62%|██████▎   | 125/200 [1:06:45<39:56, 31.95s/it] 63%|██████▎   | 126/200 [1:07:17<39:22, 31.93s/it] 64%|██████▎   | 127/200 [1:07:49<38:54, 31.99s/it] 64%|██████▍   | 128/200 [1:08:21<38:20, 31.95s/it] 64%|██████▍   | 129/200 [1:08:53<37:51, 32.00s/it] 65%|██████▌   | 130/200 [1:09:25<37:18, 31.97s/it] 66%|██████▌   | 131/200 [1:09:57<36:49, 32.03s/it] 66%|██████▌   | 132/200 [1:10:29<36:15, 32.00s/it] 66%|██████▋   | 133/200 [1:11:01<35:46, 32.04s/it] 67%|██████▋   | 134/200 [1:11:33<35:11, 31.99s/it] 68%|██████▊   | 135/200 [1:12:05<34:43, 32.06s/it] 68%|██████▊   | 136/200 [1:12:37<34:11, 32.06s/it] 68%|██████▊   | 137/200 [1:13:09<33:40, 32.08s/it] 69%|██████▉   | 138/200 [1:13:41<33:09, 32.08s/it] 70%|██████▉   | 139/200 [1:14:13<32:35, 32.06s/it] 70%|███████   | 140/200 [1:14:45<32:04, 32.08s/it] 70%|███████   | 141/200 [1:15:17<31:28, 32.01s/it] 71%|███████   | 142/200 [1:15:49<30:58, 32.05s/it] 72%|███████▏  | 143/200 [1:16:21<30:26, 32.05s/it] 72%|███████▏  | 144/200 [1:16:54<29:59, 32.14s/it] 72%|███████▎  | 145/200 [1:17:26<29:28, 32.16s/it] 73%|███████▎  | 146/200 [1:17:58<28:53, 32.10s/it] 74%|███████▎  | 147/200 [1:18:30<28:15, 31.98s/it] 74%|███████▍  | 148/200 [1:19:02<27:48, 32.08s/it] 74%|███████▍  | 149/200 [1:19:34<27:12, 32.01s/it] 75%|███████▌  | 150/200 [1:20:06<26:41, 32.03s/it] 76%|███████▌  | 151/200 [1:20:38<26:10, 32.04s/it] 76%|███████▌  | 152/200 [1:21:10<25:36, 32.01s/it] 76%|███████▋  | 153/200 [1:21:42<25:05, 32.03s/it] 77%|███████▋  | 154/200 [1:22:14<24:29, 31.95s/it] 78%|███████▊  | 155/200 [1:22:46<23:59, 31.99s/it] 78%|███████▊  | 156/200 [1:23:18<23:28, 32.01s/it] 78%|███████▊  | 157/200 [1:23:50<22:58, 32.06s/it] 79%|███████▉  | 158/200 [1:24:22<22:25, 32.04s/it] 80%|███████▉  | 159/200 [1:24:55<21:59, 32.19s/it] 80%|████████  | 160/200 [1:25:27<21:30, 32.27s/it] 80%|████████  | 161/200 [1:25:59<20:57, 32.23s/it] 81%|████████  | 162/200 [1:26:31<20:19, 32.09s/it] 82%|████████▏ | 163/200 [1:27:03<19:46, 32.07s/it] 82%|████████▏ | 164/200 [1:27:35<19:13, 32.03s/it] 82%|████████▎ | 165/200 [1:28:07<18:38, 31.95s/it] 83%|████████▎ | 166/200 [1:28:39<18:06, 31.95s/it] 84%|████████▎ | 167/200 [1:29:10<17:32, 31.90s/it] 84%|████████▍ | 168/200 [1:29:42<17:01, 31.94s/it] 84%|████████▍ | 169/200 [1:30:14<16:28, 31.89s/it] 85%|████████▌ | 170/200 [1:30:46<15:58, 31.94s/it] 86%|████████▌ | 171/200 [1:31:18<15:24, 31.88s/it] 86%|████████▌ | 172/200 [1:31:50<14:52, 31.86s/it] 86%|████████▋ | 173/200 [1:32:21<14:17, 31.75s/it] 87%|████████▋ | 174/200 [1:32:53<13:43, 31.68s/it] 88%|████████▊ | 175/200 [1:33:24<13:10, 31.62s/it] 88%|████████▊ | 176/200 [1:33:56<12:39, 31.64s/it] 88%|████████▊ | 177/200 [1:34:28<12:11, 31.80s/it] 89%|████████▉ | 178/200 [1:35:00<11:37, 31.69s/it] 90%|████████▉ | 179/200 [1:35:31<11:03, 31.58s/it] 90%|█████████ | 180/200 [1:36:02<10:29, 31.45s/it] 90%|█████████ | 181/200 [1:36:34<09:58, 31.53s/it] 91%|█████████ | 182/200 [1:37:05<09:26, 31.48s/it] 92%|█████████▏| 183/200 [1:37:37<08:54, 31.44s/it] 92%|█████████▏| 184/200 [1:38:07<08:20, 31.28s/it] 92%|█████████▎| 185/200 [1:38:39<07:52, 31.51s/it] 93%|█████████▎| 186/200 [1:39:11<07:21, 31.55s/it] 94%|█████████▎| 187/200 [1:39:43<06:50, 31.60s/it] 94%|█████████▍| 188/200 [1:40:14<06:17, 31.50s/it] 94%|█████████▍| 189/200 [1:40:46<05:47, 31.57s/it] 95%|█████████▌| 190/200 [1:41:17<05:15, 31.58s/it] 96%|█████████▌| 191/200 [1:41:49<04:44, 31.61s/it] 96%|█████████▌| 192/200 [1:42:20<04:11, 31.46s/it] 96%|█████████▋| 193/200 [1:42:52<03:40, 31.49s/it] 97%|█████████▋| 194/200 [1:43:23<03:09, 31.56s/it] 98%|█████████▊| 195/200 [1:43:55<02:37, 31.57s/it] 98%|█████████▊| 196/200 [1:44:26<02:06, 31.52s/it] 98%|█████████▊| 197/200 [1:44:58<01:34, 31.44s/it] 99%|█████████▉| 198/200 [1:45:29<01:02, 31.49s/it]100%|█████████▉| 199/200 [1:46:01<00:31, 31.41s/it]100%|██████████| 200/200 [1:46:32<00:00, 31.39s/it]100%|██████████| 200/200 [1:46:32<00:00, 31.96s/it]
50
50
number of selected users 50
Global Trainning Accurancy: 0.10068887632629227
Global Trainning Loss: 2.303131833076477
Global test accurancy: 0.10112996285527823
Global test_loss: 2.303119649887085
Global Precision: 0.010307445762540174
Global Recall: 0.10112996285527823
Global f1score: 0.01869639286065155
50
50
number of selected users 50
Global Trainning Accurancy: 0.10059622593576044
Global Trainning Loss: 2.3029969835281374
Global test accurancy: 0.1008561916592123
Global test_loss: 2.3029914808273317
Global Precision: 0.018001741788755438
Global Recall: 0.1008561916592123
Global f1score: 0.01985571081468149
50
50
number of selected users 50
Global Trainning Accurancy: 0.10085580414318515
Global Trainning Loss: 2.3028870534896853
Global test accurancy: 0.10020758755576484
Global test_loss: 2.3028879308700563
Global Precision: 0.020569240851179248
Global Recall: 0.10020758755576484
Global f1score: 0.028675336429613806
50
50
number of selected users 50
Global Trainning Accurancy: 0.10298798902322767
Global Trainning Loss: 2.302797837257385
Global test accurancy: 0.10120490495094345
Global test_loss: 2.3028046131134032
Global Precision: 0.020603978909302108
Global Recall: 0.10120490495094345
Global f1score: 0.03415418025604473
50
50
number of selected users 50
Global Trainning Accurancy: 0.10188628918875559
Global Trainning Loss: 2.302725648880005
Global test accurancy: 0.09949734977602943
Global test_loss: 2.302737808227539
Global Precision: 0.020047666627514563
Global Recall: 0.09949734977602943
Global f1score: 0.030463087909806594
50
50
number of selected users 50
Global Trainning Accurancy: 0.10088414062531305
Global Trainning Loss: 2.302667746543884
Global test accurancy: 0.09936301506318192
Global test_loss: 2.302684850692749
Global Precision: 0.017874371715066825
Global Recall: 0.09936301506318192
Global f1score: 0.022588744991601246
50
50
number of selected users 50
Global Trainning Accurancy: 0.10028483185322581
Global Trainning Loss: 2.302620768547058
Global test accurancy: 0.09925538630957483
Global test_loss: 2.3026429653167724
Global Precision: 0.014143651793814794
Global Recall: 0.09925538630957483
Global f1score: 0.01919808159919917
50
50
number of selected users 50
Global Trainning Accurancy: 0.10040791005070827
Global Trainning Loss: 2.3025833415985106
Global test accurancy: 0.09951357566748446
Global test_loss: 2.3026102924346925
Global Precision: 0.011895497481527509
Global Recall: 0.09951357566748446
Global f1score: 0.01839257610840797
50
50
number of selected users 50
Global Trainning Accurancy: 0.10049240460720076
Global Trainning Loss: 2.3025532293319704
Global test accurancy: 0.09985234360894285
Global test_loss: 2.302584910392761
Global Precision: 0.011925715704710106
Global Recall: 0.09985234360894285
Global f1score: 0.018448130581681925
50
50
number of selected users 50
Global Trainning Accurancy: 0.10117818129913894
Global Trainning Loss: 2.3025291776657104
Global test accurancy: 0.09936759847743937
Global test_loss: 2.302565312385559
Global Precision: 0.013852699914255855
Global Recall: 0.09936759847743937
Global f1score: 0.01880828813479922
50
50
number of selected users 50
Global Trainning Accurancy: 0.10231579933618011
Global Trainning Loss: 2.3025101900100706
Global test accurancy: 0.09986020855562665
Global test_loss: 2.3025502300262453
Global Precision: 0.02094593831314407
Global Recall: 0.09986020855562665
Global f1score: 0.027821001227807268
50
50
number of selected users 50
Global Trainning Accurancy: 0.10495386553667756
Global Trainning Loss: 2.302495198249817
Global test accurancy: 0.10563932054347014
Global test_loss: 2.30253897190094
Global Precision: 0.02186137917645546
Global Recall: 0.10563932054347014
Global f1score: 0.035062121775764274
50
50
number of selected users 50
Global Trainning Accurancy: 0.10491322264572897
Global Trainning Loss: 2.3024833679199217
Global test accurancy: 0.10417993477477945
Global test_loss: 2.3025306606292726
Global Precision: 0.021179240886003467
Global Recall: 0.10417993477477945
Global f1score: 0.03496513946249861
50
50
number of selected users 50
Global Trainning Accurancy: 0.10421270769225519
Global Trainning Loss: 2.3024740028381347
Global test accurancy: 0.10154049464682008
Global test_loss: 2.302524781227112
Global Precision: 0.020572795822300708
Global Recall: 0.10154049464682008
Global f1score: 0.031191774677237667
50
50
number of selected users 50
Global Trainning Accurancy: 0.10189408546280658
Global Trainning Loss: 2.302466421127319
Global test accurancy: 0.10119315413873324
Global test_loss: 2.302520818710327
Global Precision: 0.021642092680950086
Global Recall: 0.10119315413873324
Global f1score: 0.025448512341879313
50
50
number of selected users 50
Global Trainning Accurancy: 0.10149709690521615
Global Trainning Loss: 2.3024603605270384
Global test accurancy: 0.10058572381079554
Global test_loss: 2.302518534660339
Global Precision: 0.025477693460378054
Global Recall: 0.10058572381079554
Global f1score: 0.02067354945005676
50
50
number of selected users 50
Global Trainning Accurancy: 0.10106120444040811
Global Trainning Loss: 2.302455244064331
Global test accurancy: 0.10111514244616963
Global test_loss: 2.3025173330307007
Global Precision: 0.017998097269492096
Global Recall: 0.10111514244616963
Global f1score: 0.019337219185687662
50
50
number of selected users 50
Global Trainning Accurancy: 0.10103248799207
Global Trainning Loss: 2.302450737953186
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302516837120056
Global Precision: 0.010286211795820194
Global Recall: 0.1007637206371257
Global f1score: 0.018647538041386733
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3024467420578003
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302517070770264
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302443056106567
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302517352104187
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3024395751953124
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025177240371706
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.30243604183197
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025181484222412
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302432403564453
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302518358230591
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302428865432739
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302518572807312
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3024250268936157
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302518434524536
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3024208974838256
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025182104110717
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302416343688965
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302517523765564
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3024115896224977
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025167036056517
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3024066638946534
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302515687942505
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3024012660980224
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302514362335205
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302395362854004
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025124740600584
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302388896942139
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025101804733277
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3023818731307983
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025072765350343
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302374529838562
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302504119873047
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302366590499878
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3025005626678468
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3023584270477295
Global test accurancy: 0.1007637206371257
Global test_loss: 2.30249680519104
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3023497438430787
Global test accurancy: 0.1007637206371257
Global test_loss: 2.30249303817749
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3023407316207884
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302489171028137
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302331233024597
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024851942062377
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302321639060974
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024813652038576
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.30231219291687
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302477030754089
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3023023414611816
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024722385406493
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302292199134827
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302466912269592
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302281765937805
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302461247444153
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3022708463668824
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024551916122435
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3022600507736204
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024489164352415
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3022488260269167
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024426031112672
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302237434387207
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302436170578003
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.302225866317749
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024296045303343
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.1010046715803871
Global Trainning Loss: 2.3022144746780397
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302423062324524
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.10097482083411845
Global Trainning Loss: 2.3022028589248658
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024161863327026
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.10097482083411845
Global Trainning Loss: 2.3021911430358886
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302409439086914
Global Precision: 0.010283891186373115
Global Recall: 0.1007637206371257
Global f1score: 0.01864366051751119
50
50
number of selected users 50
Global Trainning Accurancy: 0.10100718329366537
Global Trainning Loss: 2.302179160118103
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3024025917053224
Global Precision: 0.010284799194276415
Global Recall: 0.1007637206371257
Global f1score: 0.018645149463575605
50
50
number of selected users 50
Global Trainning Accurancy: 0.10100718329366537
Global Trainning Loss: 2.3021669721603395
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3023954963684083
Global Precision: 0.010285175787429796
Global Recall: 0.1007637206371257
Global f1score: 0.018645772688858638
50
50
number of selected users 50
Global Trainning Accurancy: 0.10103499970534827
Global Trainning Loss: 2.3021546506881716
Global test accurancy: 0.1007637206371257
Global test_loss: 2.302388186454773
Global Precision: 0.010287842479603534
Global Recall: 0.1007637206371257
Global f1score: 0.0186501458433992
50
50
number of selected users 50
Global Trainning Accurancy: 0.10103652575723403
Global Trainning Loss: 2.3021422958374025
Global test accurancy: 0.1007637206371257
Global test_loss: 2.3023804140090944
Global Precision: 0.010287842479603534
Global Recall: 0.1007637206371257
Global f1score: 0.0186501458433992
50
50
number of selected users 50
Global Trainning Accurancy: 0.10106888821678095
Global Trainning Loss: 2.3021296739578245
Global test accurancy: 0.10069151847106071
Global test_loss: 2.3023723649978636
Global Precision: 0.010279843312196921
Global Recall: 0.10069151847106071
Global f1score: 0.018635717613536888
50
50
number of selected users 50
Global Trainning Accurancy: 0.10113150142478997
Global Trainning Loss: 2.302116827964783
Global test accurancy: 0.1006928472569933
Global test_loss: 2.3023640060424806
Global Precision: 0.012360050940658677
Global Recall: 0.1006928472569933
Global f1score: 0.018807172539681487
50
50
number of selected users 50
Global Trainning Accurancy: 0.1011042534683867
Global Trainning Loss: 2.3021038150787354
Global test accurancy: 0.10069836922862781
Global test_loss: 2.302355604171753
Global Precision: 0.013452550210883605
Global Recall: 0.10069836922862781
Global f1score: 0.018952053683647697
50
50
number of selected users 50
Global Trainning Accurancy: 0.10107670074420476
Global Trainning Loss: 2.3020906591415407
Global test accurancy: 0.10052595543552435
Global test_loss: 2.3023470973968507
Global Precision: 0.013443497403099157
Global Recall: 0.10052595543552435
Global f1score: 0.018934188233159396
50
50
number of selected users 50
Global Trainning Accurancy: 0.10102921421489028
Global Trainning Loss: 2.302077445983887
Global test accurancy: 0.10044512917737251
Global test_loss: 2.302338500022888
Global Precision: 0.013972563881631782
Global Recall: 0.10044512917737251
Global f1score: 0.019077356555907594
50
50
number of selected users 50
Global Trainning Accurancy: 0.10099259053515701
Global Trainning Loss: 2.302063889503479
Global test accurancy: 0.10045760101515816
Global test_loss: 2.3023299837112425
Global Precision: 0.01488936536655577
Global Recall: 0.10045760101515816
Global f1score: 0.019255305238466316
50
50
number of selected users 50
Global Trainning Accurancy: 0.10090512967199888
Global Trainning Loss: 2.30205002784729
Global test accurancy: 0.1003631056909639
Global test_loss: 2.3023210763931274
Global Precision: 0.01488711731826779
Global Recall: 0.1003631056909639
Global f1score: 0.019381165524422525
50
50
number of selected users 50
Global Trainning Accurancy: 0.10078734282837057
Global Trainning Loss: 2.3020360040664674
Global test accurancy: 0.1004634837946205
Global test_loss: 2.3023119354248047
Global Precision: 0.018005561120860977
Global Recall: 0.1004634837946205
Global f1score: 0.01989610579696238
50
50
number of selected users 50
Global Trainning Accurancy: 0.1007871162100467
Global Trainning Loss: 2.3020217418670654
Global test accurancy: 0.10046794575639637
Global test_loss: 2.3023026990890503
Global Precision: 0.01808141386257575
Global Recall: 0.10046794575639637
Global f1score: 0.020050122980094082
50
50
number of selected users 50
Global Trainning Accurancy: 0.1007862796467826
Global Trainning Loss: 2.30200740814209
Global test accurancy: 0.10054658884153739
Global test_loss: 2.302293047904968
Global Precision: 0.020064596466245595
Global Recall: 0.10054658884153739
Global f1score: 0.02048755494229171
50
50
number of selected users 50
Global Trainning Accurancy: 0.10076007916346716
Global Trainning Loss: 2.301992712020874
Global test accurancy: 0.1005428359562626
Global test_loss: 2.302283205986023
Global Precision: 0.020570264158563088
Global Recall: 0.1005428359562626
Global f1score: 0.02088672812490483
50
50
number of selected users 50
Global Trainning Accurancy: 0.10105915160406358
Global Trainning Loss: 2.3019775629043577
Global test accurancy: 0.1006491104059038
Global test_loss: 2.3022730922698975
Global Precision: 0.02109662320579438
Global Recall: 0.1006491104059038
Global f1score: 0.02136542664900657
50
50
number of selected users 50
Global Trainning Accurancy: 0.10132681327954546
Global Trainning Loss: 2.3019621658325193
Global test accurancy: 0.10078968959215377
Global test_loss: 2.302262945175171
Global Precision: 0.021079688902230578
Global Recall: 0.10078968959215377
Global f1score: 0.021707906158877587
50
50
number of selected users 50
Global Trainning Accurancy: 0.1017608068897147
Global Trainning Loss: 2.3019462203979493
Global test accurancy: 0.10114329636268117
Global test_loss: 2.302252779006958
Global Precision: 0.022157575680559833
Global Recall: 0.10114329636268117
Global f1score: 0.022653633383408367
50
50
number of selected users 50
Global Trainning Accurancy: 0.10193816847455041
Global Trainning Loss: 2.3019298696517945
Global test accurancy: 0.10085821355995138
Global test_loss: 2.3022420024871826
Global Precision: 0.021029251921618235
Global Recall: 0.10085821355995138
Global f1score: 0.022662996945004586
50
50
number of selected users 50
Global Trainning Accurancy: 0.10197448615345615
Global Trainning Loss: 2.30191312789917
Global test accurancy: 0.10135181211222327
Global test_loss: 2.3022310304641724
Global Precision: 0.022872926324790807
Global Recall: 0.10135181211222327
Global f1score: 0.023975020378107316
50
50
number of selected users 50
Global Trainning Accurancy: 0.1020800982620854
Global Trainning Loss: 2.3018961477279665
Global test accurancy: 0.1015413610635633
Global test_loss: 2.3022196817398073
Global Precision: 0.022850691867055205
Global Recall: 0.1015413610635633
Global f1score: 0.024508815900091255
50
50
number of selected users 50
Global Trainning Accurancy: 0.1023480685446509
Global Trainning Loss: 2.3018788051605226
Global test accurancy: 0.1015662007494327
Global test_loss: 2.302208003997803
Global Precision: 0.022643608491058995
Global Recall: 0.1015662007494327
Global f1score: 0.024915798741014388
50
50
number of selected users 50
Global Trainning Accurancy: 0.10262972435696727
Global Trainning Loss: 2.301861047744751
Global test accurancy: 0.10171885898715698
Global test_loss: 2.302196068763733
Global Precision: 0.02321083574254588
Global Recall: 0.10171885898715698
Global f1score: 0.025844589927351877
50
50
number of selected users 50
Global Trainning Accurancy: 0.10272988262955506
Global Trainning Loss: 2.3018429470062256
Global test accurancy: 0.10190079175556896
Global test_loss: 2.302184052467346
Global Precision: 0.023278904282292158
Global Recall: 0.10190079175556896
Global f1score: 0.026516418280060374
50
50
number of selected users 50
Global Trainning Accurancy: 0.10260514627835497
Global Trainning Loss: 2.3018242740631103
Global test accurancy: 0.10234828200969963
Global test_loss: 2.3021717071533203
Global Precision: 0.023370334340323436
Global Recall: 0.10234828200969963
Global f1score: 0.02721325860925192
50
50
number of selected users 50
Global Trainning Accurancy: 0.10282092771548243
Global Trainning Loss: 2.3018052339553834
Global test accurancy: 0.10259833251800829
Global test_loss: 2.302158989906311
Global Precision: 0.023466909897035725
Global Recall: 0.10259833251800829
Global f1score: 0.02788124844976535
50
50
number of selected users 50
Global Trainning Accurancy: 0.10332977158439322
Global Trainning Loss: 2.3017856073379517
Global test accurancy: 0.10289303242286794
Global test_loss: 2.3021458530426027
Global Precision: 0.023054111135482235
Global Recall: 0.10289303242286794
Global f1score: 0.028083845427974832
50
50
number of selected users 50
Global Trainning Accurancy: 0.10366314046129461
Global Trainning Loss: 2.3017656660079955
Global test accurancy: 0.10295151804813961
Global test_loss: 2.3021324682235718
Global Precision: 0.023112280190414884
Global Recall: 0.10295151804813961
Global f1score: 0.02871498732776723
50
50
number of selected users 50
Global Trainning Accurancy: 0.10382544165691587
Global Trainning Loss: 2.301745276451111
Global test accurancy: 0.10322005645530315
Global test_loss: 2.3021187496185305
Global Precision: 0.025745873608920552
Global Recall: 0.10322005645530315
Global f1score: 0.0292822005326587
50
50
number of selected users 50
Global Trainning Accurancy: 0.10397167366089187
Global Trainning Loss: 2.301724362373352
Global test accurancy: 0.10347195246953056
Global test_loss: 2.3021043729782105
Global Precision: 0.02856193503362291
Global Recall: 0.10347195246953056
Global f1score: 0.030221998600231736
50
50
number of selected users 50
Global Trainning Accurancy: 0.10412048295196567
Global Trainning Loss: 2.3017028999328613
Global test accurancy: 0.10418622759993491
Global test_loss: 2.302089524269104
Global Precision: 0.029015533516046195
Global Recall: 0.10418622759993491
Global f1score: 0.031201374824694185
50
50
number of selected users 50
Global Trainning Accurancy: 0.104095266025213
Global Trainning Loss: 2.301681218147278
Global test accurancy: 0.10423223658365954
Global test_loss: 2.302074728012085
Global Precision: 0.03019306781512772
Global Recall: 0.10423223658365954
Global f1score: 0.03191779016817247
50
50
number of selected users 50
Global Trainning Accurancy: 0.10430081127403147
Global Trainning Loss: 2.3016590595245363
Global test accurancy: 0.10444864371793253
Global test_loss: 2.3020595598220823
Global Precision: 0.030054455000793394
Global Recall: 0.10444864371793253
Global f1score: 0.03219168740019184
50
50
number of selected users 50
Global Trainning Accurancy: 0.10471051963984891
Global Trainning Loss: 2.301636528968811
Global test accurancy: 0.10482049057860685
Global test_loss: 2.302043972015381
Global Precision: 0.03041929789414424
Global Recall: 0.10482049057860685
Global f1score: 0.03258905393853797
50
50
number of selected users 50
Global Trainning Accurancy: 0.10453765257235181
Global Trainning Loss: 2.3016135835647584
Global test accurancy: 0.10502252423122353
Global test_loss: 2.3020280170440675
Global Precision: 0.030362844477714528
Global Recall: 0.10502252423122353
Global f1score: 0.032888212899935806
50
50
number of selected users 50
Global Trainning Accurancy: 0.10482168983039833
Global Trainning Loss: 2.3015901851654053
Global test accurancy: 0.10438740303570561
Global test_loss: 2.3020119285583496
Global Precision: 0.029945366338708083
Global Recall: 0.10438740303570561
Global f1score: 0.032746528556237206
50
50
number of selected users 50
Global Trainning Accurancy: 0.10488673071168367
Global Trainning Loss: 2.3015664052963256
Global test accurancy: 0.1047558342565443
Global test_loss: 2.301995801925659
Global Precision: 0.02909777325872691
Global Recall: 0.1047558342565443
Global f1score: 0.033235443717631104
50
50
number of selected users 50
Global Trainning Accurancy: 0.1051929207781358
Global Trainning Loss: 2.3015422010421753
Global test accurancy: 0.10437928165875705
Global test_loss: 2.3019792318344114
Global Precision: 0.029006508239846962
Global Recall: 0.10437928165875705
Global f1score: 0.03334000765566053
50
50
number of selected users 50
Global Trainning Accurancy: 0.10567163946922618
Global Trainning Loss: 2.301517381668091
Global test accurancy: 0.10442521831027013
Global test_loss: 2.3019622659683225
Global Precision: 0.03023439122268833
Global Recall: 0.10442521831027013
Global f1score: 0.033821550589679054
50
50
number of selected users 50
Global Trainning Accurancy: 0.1058289573175936
Global Trainning Loss: 2.3014923095703126
Global test accurancy: 0.10470695252117702
Global test_loss: 2.301945376396179
Global Precision: 0.03072383743456282
Global Recall: 0.10470695252117702
Global f1score: 0.03415265191640861
50
50
number of selected users 50
Global Trainning Accurancy: 0.10564259437076719
Global Trainning Loss: 2.3014667320251463
Global test accurancy: 0.10499363556201657
Global test_loss: 2.301928176879883
Global Precision: 0.03565270888343065
Global Recall: 0.10499363556201657
Global f1score: 0.03480943035794352
50
50
number of selected users 50
Global Trainning Accurancy: 0.10557713039328617
Global Trainning Loss: 2.301440658569336
Global test accurancy: 0.10526753083976864
Global test_loss: 2.3019107151031495
Global Precision: 0.03580674041469331
Global Recall: 0.10526753083976864
Global f1score: 0.03524199556922188
50
50
number of selected users 50
Global Trainning Accurancy: 0.10560090835194555
Global Trainning Loss: 2.301414017677307
Global test accurancy: 0.10556114375148325
Global test_loss: 2.301892795562744
Global Precision: 0.036953474811086566
Global Recall: 0.10556114375148325
Global f1score: 0.03565117302931795
50
50
number of selected users 50
Global Trainning Accurancy: 0.10557745377386828
Global Trainning Loss: 2.3013868379592894
Global test accurancy: 0.1056379352907533
Global test_loss: 2.3018746328353883
Global Precision: 0.0378647679366268
Global Recall: 0.1056379352907533
Global f1score: 0.03640551095868184
50
50
number of selected users 50
Global Trainning Accurancy: 0.10562017938149561
Global Trainning Loss: 2.301359214782715
Global test accurancy: 0.10552021110122604
Global test_loss: 2.301856417655945
Global Precision: 0.036973331719449255
Global Recall: 0.10552021110122604
Global f1score: 0.03668819203348177
50
50
number of selected users 50
Global Trainning Accurancy: 0.10583547582477353
Global Trainning Loss: 2.301331052780151
Global test accurancy: 0.105050545667802
Global test_loss: 2.301837849617004
Global Precision: 0.03510627688021527
Global Recall: 0.105050545667802
Global f1score: 0.0369175456992689
50
50
number of selected users 50
Global Trainning Accurancy: 0.10598033816628522
Global Trainning Loss: 2.3013022756576538
Global test accurancy: 0.10559390289472703
Global test_loss: 2.301818995475769
Global Precision: 0.03596255021986472
Global Recall: 0.10559390289472703
Global f1score: 0.03748310732888561
50
50
number of selected users 50
Global Trainning Accurancy: 0.10630309883435554
Global Trainning Loss: 2.3012730407714845
Global test accurancy: 0.10580076497745208
Global test_loss: 2.3017999267578126
Global Precision: 0.03631802685441765
Global Recall: 0.10580076497745208
Global f1score: 0.03804419566201686
50
50
number of selected users 50
Global Trainning Accurancy: 0.10662615634401774
Global Trainning Loss: 2.3012429761886595
Global test accurancy: 0.1056648756169471
Global test_loss: 2.3017805862426757
Global Precision: 0.03734162874551971
Global Recall: 0.1056648756169471
Global f1score: 0.03841753629598367
50
50
number of selected users 50
Global Trainning Accurancy: 0.10675630517162063
Global Trainning Loss: 2.3012124824523927
Global test accurancy: 0.10580027123726125
Global test_loss: 2.3017609167099
Global Precision: 0.04083231496411657
Global Recall: 0.10580027123726125
Global f1score: 0.03879026748969051
50
50
number of selected users 50
Global Trainning Accurancy: 0.10720087371231533
Global Trainning Loss: 2.3011813163757324
Global test accurancy: 0.1060419069655473
Global test_loss: 2.3017409372329714
Global Precision: 0.04134914643250531
Global Recall: 0.1060419069655473
Global f1score: 0.03941135677854183
50
50
number of selected users 50
Global Trainning Accurancy: 0.10730049122883273
Global Trainning Loss: 2.301149344444275
Global test accurancy: 0.10657807194576839
Global test_loss: 2.3017203283309935
Global Precision: 0.04148594740325071
Global Recall: 0.10657807194576839
Global f1score: 0.04012986490328254
50
50
number of selected users 50
Global Trainning Accurancy: 0.10709883345652667
Global Trainning Loss: 2.301116623878479
Global test accurancy: 0.10630912713119135
Global test_loss: 2.3016990184783936
Global Precision: 0.04077161874312508
Global Recall: 0.10630912713119135
Global f1score: 0.040292866842423475
50
50
number of selected users 50
Global Trainning Accurancy: 0.1074721192805215
Global Trainning Loss: 2.3010831928253173
Global test accurancy: 0.10640740319233338
Global test_loss: 2.301677074432373
Global Precision: 0.04215962345916779
Global Recall: 0.10640740319233338
Global f1score: 0.040823651799001
50
50
number of selected users 50
Global Trainning Accurancy: 0.10785473049294188
Global Trainning Loss: 2.301049118041992
Global test accurancy: 0.10599686707712455
Global test_loss: 2.301654839515686
Global Precision: 0.04215527983754829
Global Recall: 0.10599686707712455
Global f1score: 0.0410699436117905
50
50
number of selected users 50
Global Trainning Accurancy: 0.10781549990353712
Global Trainning Loss: 2.3010141897201537
Global test accurancy: 0.1061937335174445
Global test_loss: 2.3016319847106934
Global Precision: 0.04435424726469289
Global Recall: 0.1061937335174445
Global f1score: 0.04186614944856057
50
50
number of selected users 50
Global Trainning Accurancy: 0.1082983655305752
Global Trainning Loss: 2.3009788274765013
Global test accurancy: 0.10669166276146645
Global test_loss: 2.3016087102890013
Global Precision: 0.04661578002519389
Global Recall: 0.10669166276146645
Global f1score: 0.04272775462415205
50
50
number of selected users 50
Global Trainning Accurancy: 0.10847797244574994
Global Trainning Loss: 2.300942463874817
Global test accurancy: 0.10664301523113544
Global test_loss: 2.3015848922729494
Global Precision: 0.04840352150326734
Global Recall: 0.10664301523113544
Global f1score: 0.043309447566135036
50
50
number of selected users 50
Global Trainning Accurancy: 0.10874759086224921
Global Trainning Loss: 2.300905442237854
Global test accurancy: 0.10717035123807059
Global test_loss: 2.301560878753662
Global Precision: 0.04926287083912047
Global Recall: 0.10717035123807059
Global f1score: 0.044282995886882955
50
50
number of selected users 50
Global Trainning Accurancy: 0.10941318081456233
Global Trainning Loss: 2.30086754322052
Global test accurancy: 0.10734201237066167
Global test_loss: 2.3015361547470095
Global Precision: 0.05148611869463923
Global Recall: 0.10734201237066167
Global f1score: 0.04535885262203531
50
50
number of selected users 50
Global Trainning Accurancy: 0.10970174265990182
Global Trainning Loss: 2.300828971862793
Global test accurancy: 0.10749898807278278
Global test_loss: 2.3015111541748046
Global Precision: 0.052303220360810296
Global Recall: 0.10749898807278278
Global f1score: 0.04591666895936558
50
50
number of selected users 50
Global Trainning Accurancy: 0.11032933744015261
Global Trainning Loss: 2.3007893562316895
Global test accurancy: 0.10746951206178429
Global test_loss: 2.3014858865737917
Global Precision: 0.05207918987026141
Global Recall: 0.10746951206178429
Global f1score: 0.046648608726119825
50
50
number of selected users 50
Global Trainning Accurancy: 0.11091624735840844
Global Trainning Loss: 2.3007489967346193
Global test accurancy: 0.10782873902503591
Global test_loss: 2.3014607000350953
Global Precision: 0.052389055281920845
Global Recall: 0.10782873902503591
Global f1score: 0.04787853060688559
50
50
number of selected users 50
Global Trainning Accurancy: 0.11118638615357332
Global Trainning Loss: 2.300707368850708
Global test accurancy: 0.10881434817811256
Global test_loss: 2.3014349126815796
Global Precision: 0.052373122788456905
Global Recall: 0.10881434817811256
Global f1score: 0.04896209711036488
50
50
number of selected users 50
Global Trainning Accurancy: 0.111192653089855
Global Trainning Loss: 2.3006653690338137
Global test accurancy: 0.10854796560332713
Global test_loss: 2.3014083433151247
Global Precision: 0.051644797691436886
Global Recall: 0.10854796560332713
Global f1score: 0.0495385190010939
50
50
number of selected users 50
Global Trainning Accurancy: 0.1114553547377429
Global Trainning Loss: 2.300622797012329
Global test accurancy: 0.10872339140838462
Global test_loss: 2.301381630897522
Global Precision: 0.05189343400966085
Global Recall: 0.10872339140838462
Global f1score: 0.0500812932684104
50
50
number of selected users 50
Global Trainning Accurancy: 0.11172508376813838
Global Trainning Loss: 2.300579266548157
Global test accurancy: 0.1083340228221395
Global test_loss: 2.3013544130325316
Global Precision: 0.049697276357649846
Global Recall: 0.1083340228221395
Global f1score: 0.05015139651775068
50
50
number of selected users 50
Global Trainning Accurancy: 0.11225850060681607
Global Trainning Loss: 2.3005353355407716
Global test accurancy: 0.1080028281595699
Global test_loss: 2.3013271045684816
Global Precision: 0.04921017721261467
Global Recall: 0.1080028281595699
Global f1score: 0.050468006942482053
50
50
number of selected users 50
Global Trainning Accurancy: 0.11248144025623671
Global Trainning Loss: 2.3004907989501953
Global test accurancy: 0.10834570571145821
Global test_loss: 2.301299185752869
Global Precision: 0.04984401498051093
Global Recall: 0.10834570571145821
Global f1score: 0.051411539600591735
50
50
number of selected users 50
Global Trainning Accurancy: 0.1130260484151834
Global Trainning Loss: 2.300445694923401
Global test accurancy: 0.10841303356842466
Global test_loss: 2.3012709712982176
Global Precision: 0.04951961285091857
Global Recall: 0.10841303356842466
Global f1score: 0.05202274514991928
50
50
number of selected users 50
Global Trainning Accurancy: 0.11339559462455764
Global Trainning Loss: 2.300399842262268
Global test accurancy: 0.1093785499346092
Global test_loss: 2.3012424993515013
Global Precision: 0.05026391142567519
Global Recall: 0.1093785499346092
Global f1score: 0.05350564083896737
50
50
number of selected users 50
Global Trainning Accurancy: 0.1134500219276108
Global Trainning Loss: 2.300353274345398
Global test accurancy: 0.10986396576072814
Global test_loss: 2.3012138557434083
Global Precision: 0.0505029057367819
Global Recall: 0.10986396576072814
Global f1score: 0.05463458982035924
50
50
number of selected users 50
Global Trainning Accurancy: 0.11368540193289825
Global Trainning Loss: 2.3003058099746703
Global test accurancy: 0.10971661740370037
Global test_loss: 2.3011844873428347
Global Precision: 0.04974634469911323
Global Recall: 0.10971661740370037
Global f1score: 0.05492564702267505
50
50
number of selected users 50
Global Trainning Accurancy: 0.11424092930792111
Global Trainning Loss: 2.300257601737976
Global test accurancy: 0.10932816296680328
Global test_loss: 2.3011546611785887
Global Precision: 0.0494901704762278
Global Recall: 0.10932816296680328
Global f1score: 0.055305703091240735
50
50
number of selected users 50
Global Trainning Accurancy: 0.11439343535038352
Global Trainning Loss: 2.300208683013916
Global test accurancy: 0.10948911047785402
Global test_loss: 2.301124415397644
Global Precision: 0.05156858552094117
Global Recall: 0.10948911047785402
Global f1score: 0.05621797581116856
50
50
number of selected users 50
Global Trainning Accurancy: 0.11493608444585247
Global Trainning Loss: 2.3001589822769164
Global test accurancy: 0.11011491970742655
Global test_loss: 2.3010938358306885
Global Precision: 0.05200642576511512
Global Recall: 0.11011491970742655
Global f1score: 0.057187266513072335
50
50
number of selected users 50
Global Trainning Accurancy: 0.11524628142835616
Global Trainning Loss: 2.3001087427139284
Global test accurancy: 0.10979906457280883
Global test_loss: 2.3010631084442137
Global Precision: 0.05100190502674673
Global Recall: 0.10979906457280883
Global f1score: 0.0571539845314197
50
50
number of selected users 50
Global Trainning Accurancy: 0.11506074248532061
Global Trainning Loss: 2.3000577211380007
Global test accurancy: 0.10917488505666627
Global test_loss: 2.301032018661499
Global Precision: 0.05278239389531597
Global Recall: 0.10917488505666627
Global f1score: 0.057183483811542916
50
50
number of selected users 50
Global Trainning Accurancy: 0.1149699978565603
Global Trainning Loss: 2.3000060319900513
Global test accurancy: 0.10906814602425129
Global test_loss: 2.3010013723373413
Global Precision: 0.053239266217029575
Global Recall: 0.10906814602425129
Global f1score: 0.0576120478007802
50
50
number of selected users 50
Global Trainning Accurancy: 0.11501225927084012
Global Trainning Loss: 2.2999531507492064
Global test accurancy: 0.11017198202039458
Global test_loss: 2.300970230102539
Global Precision: 0.05425253024951018
Global Recall: 0.11017198202039458
Global f1score: 0.05842211304151947
50
50
number of selected users 50
Global Trainning Accurancy: 0.11533198198522196
Global Trainning Loss: 2.2998998594284057
Global test accurancy: 0.11019437280726656
Global test_loss: 2.300937852859497
Global Precision: 0.054127473662169426
Global Recall: 0.11019437280726656
Global f1score: 0.0589708455157365
50
50
number of selected users 50
Global Trainning Accurancy: 0.11557305221764194
Global Trainning Loss: 2.2998453426361083
Global test accurancy: 0.11040451899041384
Global test_loss: 2.300905385017395
Global Precision: 0.0540790278120745
Global Recall: 0.11040451899041384
Global f1score: 0.059462879332834694
50
50
number of selected users 50
Global Trainning Accurancy: 0.11554596768640797
Global Trainning Loss: 2.299790267944336
Global test accurancy: 0.11122338603236656
Global test_loss: 2.3008729553222658
Global Precision: 0.05522362971589278
Global Recall: 0.11122338603236656
Global f1score: 0.06027419174973857
50
50
number of selected users 50
Global Trainning Accurancy: 0.11565840609085214
Global Trainning Loss: 2.2997344541549682
Global test accurancy: 0.11174056406718051
Global test_loss: 2.3008408451080324
Global Precision: 0.05551043166554343
Global Recall: 0.11174056406718051
Global f1score: 0.0612035531324291
50
50
number of selected users 50
Global Trainning Accurancy: 0.11550950390051291
Global Trainning Loss: 2.2996785497665404
Global test accurancy: 0.11219544271609247
Global test_loss: 2.3008079385757445
Global Precision: 0.05720156121946818
Global Recall: 0.11219544271609247
Global f1score: 0.061952488916033936
50
50
number of selected users 50
Global Trainning Accurancy: 0.11564685574134392
Global Trainning Loss: 2.299622130393982
Global test accurancy: 0.11196568181779117
Global test_loss: 2.300774235725403
Global Precision: 0.05761580918628726
Global Recall: 0.11196568181779117
Global f1score: 0.06226617204571203
50
50
number of selected users 50
Global Trainning Accurancy: 0.11553772181576998
Global Trainning Loss: 2.299564895629883
Global test accurancy: 0.11109028013663765
Global test_loss: 2.300740056037903
Global Precision: 0.0576510176344669
Global Recall: 0.11109028013663765
Global f1score: 0.06205359160425633
50
50
number of selected users 50
Global Trainning Accurancy: 0.11579868430938953
Global Trainning Loss: 2.299506998062134
Global test accurancy: 0.11108446584962484
Global test_loss: 2.3007057809829714
Global Precision: 0.0586931581458044
Global Recall: 0.11108446584962484
Global f1score: 0.06248018889950336
50
50
number of selected users 50
Global Trainning Accurancy: 0.11648061021216367
Global Trainning Loss: 2.299448962211609
Global test accurancy: 0.11110517421349476
Global test_loss: 2.300671877861023
Global Precision: 0.06057274395361333
Global Recall: 0.11110517421349476
Global f1score: 0.06300539918762925
50
50
number of selected users 50
Global Trainning Accurancy: 0.11703436299119874
Global Trainning Loss: 2.2993905973434448
Global test accurancy: 0.11117907325935886
Global test_loss: 2.3006373691558837
Global Precision: 0.06611184730454803
Global Recall: 0.11117907325935886
Global f1score: 0.06359319219825982
50
50
number of selected users 50
Global Trainning Accurancy: 0.11764950554338545
Global Trainning Loss: 2.2993316411972047
Global test accurancy: 0.11089919718743961
Global test_loss: 2.300602493286133
Global Precision: 0.06516045636396016
Global Recall: 0.11089919718743961
Global f1score: 0.063630458657545
50
50
number of selected users 50
Global Trainning Accurancy: 0.11772728707152913
Global Trainning Loss: 2.299270968437195
Global test accurancy: 0.11135470394609961
Global test_loss: 2.300566897392273
Global Precision: 0.06841186505847684
Global Recall: 0.11135470394609961
Global f1score: 0.0645029814171867
50
50
number of selected users 50
Global Trainning Accurancy: 0.11808638231019507
Global Trainning Loss: 2.299210133552551
Global test accurancy: 0.11229093164037465
Global test_loss: 2.3005327081680296
Global Precision: 0.07082856965603834
Global Recall: 0.11229093164037465
Global f1score: 0.06562086539409197
50
50
number of selected users 50
Global Trainning Accurancy: 0.11837167021475085
Global Trainning Loss: 2.2991474866867065
Global test accurancy: 0.11238538546094302
Global test_loss: 2.3004973840713503
Global Precision: 0.07103401380150585
Global Recall: 0.11238538546094302
Global f1score: 0.06592076039043274
50
50
number of selected users 50
Global Trainning Accurancy: 0.11889517080584032
Global Trainning Loss: 2.2990842914581298
Global test accurancy: 0.11186048034330778
Global test_loss: 2.3004644298553467
Global Precision: 0.07369067427402061
Global Recall: 0.11186048034330778
Global f1score: 0.06607622601660686
50
50
number of selected users 50
Global Trainning Accurancy: 0.11897307210839154
Global Trainning Loss: 2.2990206575393675
Global test accurancy: 0.11223041665451239
Global test_loss: 2.3004303407669067
Global Precision: 0.07568606615322816
Global Recall: 0.11223041665451239
Global f1score: 0.06676304739716897
50
50
number of selected users 50
Global Trainning Accurancy: 0.11897476654687197
Global Trainning Loss: 2.2989562225341795
Global test accurancy: 0.11234607854932266
Global test_loss: 2.300395426750183
Global Precision: 0.07779032946416352
Global Recall: 0.11234607854932266
Global f1score: 0.06763972219829663
50
50
number of selected users 50
Global Trainning Accurancy: 0.11945546552404505
Global Trainning Loss: 2.298891878128052
Global test accurancy: 0.11206988403698061
Global test_loss: 2.300358967781067
Global Precision: 0.07576550618437981
Global Recall: 0.11206988403698061
Global f1score: 0.0680803507911972
50
50
number of selected users 50
Global Trainning Accurancy: 0.11943393691333587
Global Trainning Loss: 2.298828806877136
Global test accurancy: 0.11262946070525696
Global test_loss: 2.3003225898742676
Global Precision: 0.07810949900309293
Global Recall: 0.11262946070525696
Global f1score: 0.06916485553196451
50
50
number of selected users 50
Global Trainning Accurancy: 0.11998413698822365
Global Trainning Loss: 2.2987641096115112
Global test accurancy: 0.11233527303848471
Global test_loss: 2.300284533500671
Global Precision: 0.07743888828808383
Global Recall: 0.11233527303848471
Global f1score: 0.06944179254244143
50
50
number of selected users 50
Global Trainning Accurancy: 0.12041615730576129
Global Trainning Loss: 2.2986991786956787
Global test accurancy: 0.11192356805940654
Global test_loss: 2.3002470207214354
Global Precision: 0.07718288954701825
Global Recall: 0.11192356805940654
Global f1score: 0.06969849825667543
50
50
number of selected users 50
Global Trainning Accurancy: 0.12031093401374068
Global Trainning Loss: 2.29863480091095
Global test accurancy: 0.11243515280355748
Global test_loss: 2.3002117919921874
Global Precision: 0.08316397911272969
Global Recall: 0.11243515280355748
Global f1score: 0.07134677354625203
50
50
number of selected users 50
Global Trainning Accurancy: 0.12036449870213137
Global Trainning Loss: 2.2985712909698486
Global test accurancy: 0.11293739502574177
Global test_loss: 2.3001764726638796
Global Precision: 0.08594223347858011
Global Recall: 0.11293739502574177
Global f1score: 0.07253270367994577
50
50
number of selected users 50
Global Trainning Accurancy: 0.12060232201556077
Global Trainning Loss: 2.2985069608688353
Global test accurancy: 0.11349418423106615
Global test_loss: 2.3001409435272215
Global Precision: 0.08565759491462824
Global Recall: 0.11349418423106615
Global f1score: 0.07354592852559479
50
50
number of selected users 50
Global Trainning Accurancy: 0.12126754251290549
Global Trainning Loss: 2.298443431854248
Global test accurancy: 0.1138746839294406
Global test_loss: 2.3001052379608153
Global Precision: 0.08753696083000473
Global Recall: 0.1138746839294406
Global f1score: 0.07443027611184849
50
50
number of selected users 50
Global Trainning Accurancy: 0.12095840325580141
Global Trainning Loss: 2.2983812046051026
Global test accurancy: 0.11341043944558873
Global test_loss: 2.3000709295272825
Global Precision: 0.08616951117316694
Global Recall: 0.11341043944558873
Global f1score: 0.07464783976314748
50
50
number of selected users 50
Global Trainning Accurancy: 0.12159510315270837
Global Trainning Loss: 2.2983181476593018
Global test accurancy: 0.11410545058849395
Global test_loss: 2.300035524368286
Global Precision: 0.09170828120542919
Global Recall: 0.11410545058849395
Global f1score: 0.07618441887287519
50
50
number of selected users 50
Global Trainning Accurancy: 0.12136367433791877
Global Trainning Loss: 2.298256335258484
Global test accurancy: 0.11407845760015488
Global test_loss: 2.300001273155212
Global Precision: 0.09040124447273336
Global Recall: 0.11407845760015488
Global f1score: 0.07649873852524697
50
50
number of selected users 50
Global Trainning Accurancy: 0.1214987000527079
Global Trainning Loss: 2.298194808959961
Global test accurancy: 0.11470645891001492
Global test_loss: 2.299967007637024
Global Precision: 0.09074893307551334
Global Recall: 0.11470645891001492
Global f1score: 0.07774110981747222
50
50
number of selected users 50
Global Trainning Accurancy: 0.12189528413880622
Global Trainning Loss: 2.298133382797241
Global test accurancy: 0.114730032987627
Global test_loss: 2.2999328184127807
Global Precision: 0.09076976721801606
Global Recall: 0.114730032987627
Global f1score: 0.07840011540591303
50
50
number of selected users 50
Global Trainning Accurancy: 0.12190156336226167
Global Trainning Loss: 2.2980719709396364
Global test accurancy: 0.11513582016189404
Global test_loss: 2.2998988151550295
Global Precision: 0.09115988045937921
Global Recall: 0.11513582016189404
Global f1score: 0.07934551342637487
50
50
number of selected users 50
Global Trainning Accurancy: 0.122033293194551
Global Trainning Loss: 2.2980115842819213
Global test accurancy: 0.11499449375922861
Global test_loss: 2.299866781234741
Global Precision: 0.08922157529970669
Global Recall: 0.11499449375922861
Global f1score: 0.07957806474484702
50
50
number of selected users 50
Global Trainning Accurancy: 0.12240577969193735
Global Trainning Loss: 2.2979515838623046
Global test accurancy: 0.11521161982489332
Global test_loss: 2.299836106300354
Global Precision: 0.0920535924761552
Global Recall: 0.11521161982489332
Global f1score: 0.08047052823483862
50
50
number of selected users 50
Global Trainning Accurancy: 0.12273503232253116
Global Trainning Loss: 2.297891368865967
Global test accurancy: 0.11533310147544308
Global test_loss: 2.299805612564087
Global Precision: 0.09292836269919248
Global Recall: 0.11533310147544308
Global f1score: 0.0812633065923867
50
50
number of selected users 50
Global Trainning Accurancy: 0.12322402671953046
Global Trainning Loss: 2.29783239364624
Global test accurancy: 0.11562312205672814
Global test_loss: 2.2997766447067263
Global Precision: 0.0931901446005602
Global Recall: 0.11562312205672814
Global f1score: 0.08214754014018438
50
50
number of selected users 50
Global Trainning Accurancy: 0.12339002369025472
Global Trainning Loss: 2.2977735567092896
Global test accurancy: 0.11600454064163973
Global test_loss: 2.299748158454895
Global Precision: 0.09882101418727655
Global Recall: 0.11600454064163973
Global f1score: 0.0833324421504289
50
50
number of selected users 50
Global Trainning Accurancy: 0.12335288493427014
Global Trainning Loss: 2.297714319229126
Global test accurancy: 0.11679152775085655
Global test_loss: 2.2997199487686157
Global Precision: 0.10003061224519356
Global Recall: 0.11679152775085655
Global f1score: 0.08474672631727576
50
50
number of selected users 50
Global Trainning Accurancy: 0.12360956859592458
Global Trainning Loss: 2.2976551485061645
Global test accurancy: 0.11680140816624006
Global test_loss: 2.29969286441803
Global Precision: 0.09884753867000692
Global Recall: 0.11680140816624006
Global f1score: 0.08515627353906943
50
50
number of selected users 50
Global Trainning Accurancy: 0.12356907831213118
Global Trainning Loss: 2.297595920562744
Global test accurancy: 0.11751171931592024
Global test_loss: 2.299668073654175
Global Precision: 0.09859066685587553
Global Recall: 0.11751171931592024
Global f1score: 0.0861617429536061
50
50
number of selected users 50
Global Trainning Accurancy: 0.12343815637952613
Global Trainning Loss: 2.2975353097915647
Global test accurancy: 0.11766625928813082
Global test_loss: 2.2996446323394775
Global Precision: 0.09792844527404242
Global Recall: 0.11766625928813082
Global f1score: 0.0866639631541399
50
50
number of selected users 50
Global Trainning Accurancy: 0.12398524538189577
Global Trainning Loss: 2.2974731159210204
Global test accurancy: 0.11804252882249194
Global test_loss: 2.29962197303772
Global Precision: 0.10123026342324168
Global Recall: 0.11804252882249194
Global f1score: 0.08724587261972522
50
50
number of selected users 50
Global Trainning Accurancy: 0.12419809830223588
Global Trainning Loss: 2.2974142265319824
Global test accurancy: 0.11834421310535746
Global test_loss: 2.2996028995513917
Global Precision: 0.1053119884314248
Global Recall: 0.11834421310535746
Global f1score: 0.08836026155508558
50
50
number of selected users 50
Global Trainning Accurancy: 0.12434606970851511
Global Trainning Loss: 2.297355556488037
Global test accurancy: 0.1185060080122376
Global test_loss: 2.2995835590362548
Global Precision: 0.10497616704461725
Global Recall: 0.1185060080122376
Global f1score: 0.08880600759077474
50
50
number of selected users 50
Global Trainning Accurancy: 0.12483115465323764
Global Trainning Loss: 2.297298903465271
Global test accurancy: 0.1190609471450929
Global test_loss: 2.299567532539368
Global Precision: 0.10533372876942564
Global Recall: 0.1190609471450929
Global f1score: 0.08968531842273135
50
50
number of selected users 50
Global Trainning Accurancy: 0.1246515579603375
Global Trainning Loss: 2.2972421407699586
Global test accurancy: 0.11844213350886112
Global test_loss: 2.299551639556885
Global Precision: 0.10327361839152484
Global Recall: 0.11844213350886112
Global f1score: 0.08952635482652935
50
50
number of selected users 50
Global Trainning Accurancy: 0.12492999731371486
Global Trainning Loss: 2.2971842241287233
Global test accurancy: 0.11803895285971087
Global test_loss: 2.299534273147583
Global Precision: 0.10257892904826223
Global Recall: 0.11803895285971087
Global f1score: 0.08996343830210404
50
50
number of selected users 50
Global Trainning Accurancy: 0.12465271188212351
Global Trainning Loss: 2.2971281814575195
Global test accurancy: 0.11843194429530442
Global test_loss: 2.29951943397522
Global Precision: 0.10309719480121454
Global Recall: 0.11843194429530442
Global f1score: 0.09063393644026309
50
50
number of selected users 50
Global Trainning Accurancy: 0.12478403411792456
Global Trainning Loss: 2.297072105407715
Global test accurancy: 0.11854456171484765
Global test_loss: 2.2995057916641235
Global Precision: 0.10276856359345254
Global Recall: 0.11854456171484765
Global f1score: 0.0911328256194703
50
50
number of selected users 50
Global Trainning Accurancy: 0.12500922954493773
Global Trainning Loss: 2.297016749382019
Global test accurancy: 0.11834239848214816
Global test_loss: 2.2994941425323487
Global Precision: 0.10183305009898107
Global Recall: 0.11834239848214816
Global f1score: 0.09123777433260188
50
50
number of selected users 50
Global Trainning Accurancy: 0.12472361505696014
Global Trainning Loss: 2.296960391998291
Global test accurancy: 0.11847118364230252
Global test_loss: 2.299483604431152
Global Precision: 0.10372782576613801
Global Recall: 0.11847118364230252
Global f1score: 0.09190827159280744
50
50
number of selected users 50
Global Trainning Accurancy: 0.12527123130675677
Global Trainning Loss: 2.2969047021865845
Global test accurancy: 0.11870050954957895
Global test_loss: 2.299472908973694
Global Precision: 0.10806627314398712
Global Recall: 0.11870050954957895
Global f1score: 0.09275505224757252
50
50
number of selected users 50
Global Trainning Accurancy: 0.12538840603787552
Global Trainning Loss: 2.296847925186157
Global test accurancy: 0.11920890284413294
Global test_loss: 2.2994632863998414
Global Precision: 0.11075705794966019
Global Recall: 0.11920890284413294
Global f1score: 0.09371720422452728
50
50
number of selected users 50
Global Trainning Accurancy: 0.12509555685814494
Global Trainning Loss: 2.296789927482605
Global test accurancy: 0.11862814253051601
Global test_loss: 2.2994520139694212
Global Precision: 0.113614657745385
Global Recall: 0.11862814253051601
Global f1score: 0.09384791479374835
50
50
number of selected users 50
Global Trainning Accurancy: 0.12500227117972196
Global Trainning Loss: 2.2967339992523192
Global test accurancy: 0.11799942320965932
Global test_loss: 2.299443492889404
Global Precision: 0.11330818476283583
Global Recall: 0.11799942320965932
Global f1score: 0.09388252423149823
50
50
number of selected users 50
Global Trainning Accurancy: 0.12508950252678264
Global Trainning Loss: 2.296679720878601
Global test accurancy: 0.11744564434639031
Global test_loss: 2.2994378852844237
Global Precision: 0.11292892400450384
Global Recall: 0.11744564434639031
Global f1score: 0.09345989483089702
50
50
number of selected users 50
Global Trainning Accurancy: 0.12527215391570368
Global Trainning Loss: 2.2966237306594848
Global test accurancy: 0.11767984986351354
Global test_loss: 2.2994319581985474
Global Precision: 0.11387189148417447
Global Recall: 0.11767984986351354
Global f1score: 0.09427312912844796
50
50
number of selected users 50
Global Trainning Accurancy: 0.12573264813299348
Global Trainning Loss: 2.296568040847778
Global test accurancy: 0.11785040258110775
Global test_loss: 2.299427170753479
Global Precision: 0.11493406150697656
Global Recall: 0.11785040258110775
Global f1score: 0.0948112290735628
50
50
number of selected users 50
Global Trainning Accurancy: 0.12555086104088511
Global Trainning Loss: 2.2965117359161376
Global test accurancy: 0.11820792248090156
Global test_loss: 2.2994236898422242
Global Precision: 0.11492782225301307
Global Recall: 0.11820792248090156
Global f1score: 0.09518365585066614
50
50
number of selected users 50
Global Trainning Accurancy: 0.12561665614317288
Global Trainning Loss: 2.2964552783966066
Global test accurancy: 0.11850550833654973
Global test_loss: 2.299420561790466
Global Precision: 0.11474928981336216
Global Recall: 0.11850550833654973
Global f1score: 0.09563737988750633
50
50
number of selected users 50
Global Trainning Accurancy: 0.12566717687077683
Global Trainning Loss: 2.296398482322693
Global test accurancy: 0.11835398361973679
Global test_loss: 2.299417328834534
Global Precision: 0.11394166450315549
Global Recall: 0.11835398361973679
Global f1score: 0.09575726689098023
50
50
number of selected users 50
Global Trainning Accurancy: 0.1259729726603141
Global Trainning Loss: 2.296339430809021
Global test accurancy: 0.11818495291573894
Global test_loss: 2.2994145059585573
Global Precision: 0.11478831332542012
Global Recall: 0.11818495291573894
Global f1score: 0.09600549768779545
50
50
number of selected users 50
Global Trainning Accurancy: 0.12649861541190383
Global Trainning Loss: 2.296281237602234
Global test accurancy: 0.11851567698169096
Global test_loss: 2.2994136428833007
Global Precision: 0.11553386808257175
Global Recall: 0.11851567698169096
Global f1score: 0.09653016131324928
50
50
number of selected users 50
Global Trainning Accurancy: 0.12687155849062134
Global Trainning Loss: 2.2962221908569336
Global test accurancy: 0.11819885889864244
Global test_loss: 2.2994143772125244
Global Precision: 0.11482109865218632
Global Recall: 0.11819885889864244
Global f1score: 0.09628470130930686
50
50
number of selected users 50
Global Trainning Accurancy: 0.1268226914216268
Global Trainning Loss: 2.296163969039917
Global test accurancy: 0.11780885454499963
Global test_loss: 2.2994192361831667
Global Precision: 0.11105124900794944
Global Recall: 0.11780885454499963
Global f1score: 0.09574876761686438
50
50
number of selected users 50
Global Trainning Accurancy: 0.12663387259261086
Global Trainning Loss: 2.2961056900024412
Global test accurancy: 0.11853063255291856
Global test_loss: 2.2994260358810426
Global Precision: 0.11231924123835332
Global Recall: 0.11853063255291856
Global f1score: 0.09676523001859828
50
50
number of selected users 50
Global Trainning Accurancy: 0.1266632744805828
Global Trainning Loss: 2.2960454416275025
Global test accurancy: 0.11860627013535907
Global test_loss: 2.299431576728821
Global Precision: 0.11238260859677345
Global Recall: 0.11860627013535907
Global f1score: 0.0969818203539249
50
50
number of selected users 50
Global Trainning Accurancy: 0.12684657301464847
Global Trainning Loss: 2.2959861516952516
Global test accurancy: 0.11895502298107306
Global test_loss: 2.2994389390945433
Global Precision: 0.11376693952477812
Global Recall: 0.11895502298107306
Global f1score: 0.09738416384559813
50
50
number of selected users 50
Global Trainning Accurancy: 0.1267188855681103
Global Trainning Loss: 2.2959265184402464
Global test accurancy: 0.11936548793287431
Global test_loss: 2.299446368217468
Global Precision: 0.11387912359121842
Global Recall: 0.11936548793287431
Global f1score: 0.09802480655108475
exp_no  0
0_dataset_CIFAR10_algorithm_MOON_L2_model_CNN_10_50_0.8_31_07_2024
